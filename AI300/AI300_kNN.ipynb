{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI300\n",
        "### kNN"
      ],
      "metadata": {
        "id": "QkNAIHoX6j5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "import numpy as np\n",
        "\n",
        "class MyKNN():\n",
        "  def __init__(self, num_neighbors, norm=2):\n",
        "    self.num_neighbors = num_neighbors\n",
        "    self.norm = norm\n",
        "    self.X_train = None\n",
        "    self.y_train = None\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "  def predict(self, X_test,\n",
        "              mode: Literal[\"classification\", \"regression\"] = \"classification\"):\n",
        "    distance_matrix = np.linalg.norm(X_test[:, None, :] - X_train,\n",
        "                                     ord = self.norm, axis=-1)\n",
        "    nearest_k_indices = np.argsort(distance_matrix, axis=1)[:, :self.num_neighbors]\n",
        "    nearest_k_vals = self.y_train[nearest_k_indices]\n",
        "\n",
        "    if mode == \"classification\":\n",
        "      y_pred = np.apply_along_axis(\n",
        "          lambda x: np.argmax(np.bincount(x)),\n",
        "          axis=1, arr=nearest_k_vals\n",
        "      )\n",
        "    elif mode == \"regression\":\n",
        "      y_pred = np.mean(nearest_k_vals, axis=1)\n",
        "    else:\n",
        "      raise ValueError(f\"mode must be one of ['classification', 'regression'].\"\\\n",
        "                       f\"Received: {mode}\")\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "jmnym1Y_7nJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris[\"data\"], iris[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "my_knn = MyKNN(num_neighbors=5)\n",
        "my_knn.fit(X_train, y_train)\n",
        "my_y_pred = my_knn.predict(X_test)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "diffs = (my_y_pred == y_pred)\n",
        "print(diffs) # All true so my predictions and Sklearn predictions are same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4l8d0qp895_",
        "outputId": "eaffdd89-f6ac-437a-9363-c650110eb89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "X, y = diabetes[\"data\"], diabetes[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "my_knn = MyKNN(num_neighbors=5)\n",
        "my_knn.fit(X_train, y_train)\n",
        "my_y_pred = my_knn.predict(X_test, mode=\"regression\")\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "diffs = (my_y_pred == y_pred)\n",
        "print(diffs) # All true so my predictions and Sklearn predictions are same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CaS9Zie-ImI",
        "outputId": "cd4e8ffd-e190-4d31-ff39-8ed88c838cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm not completely sure how to work out questions #4 and #5, so I was wondering how I was supposed to go about solving that? Would it possible to receive some explanation on these questions or topics to review? Thanks"
      ],
      "metadata": {
        "id": "v-O3D67Skqzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem, we will have to find an expression for $y^{(n)}$ as $N \\rightarrow \\infty$. Because $f(x)>0$ for $x\\in [0,1]$, we can compute the PDF which would be of form $\\int_0^{x_1} x f(x) dx$, where $x_1$ is the threshold that tells us what percent of the $N$ data points to use in the kNN model. We can plug in known values to get that $y^{(n)}=\\int_0^{x_1}g(x)\\frac{f(x)}{\\epsilon}dx = \\frac{1}{\\epsilon}\\int_0^{x_1}g(x)f(x)dx$. So our formula as $N\\rightarrow\\infty$ may look something like this.\n",
        "\n",
        "Part two, I think, would be looking for the error, or the distance between the predicted value and the ground truth value. So it would be $g(0)-\\frac{1}{\\epsilon}\\int_0^{x_1}g(x)f(x)dx$ using the expression from part 1."
      ],
      "metadata": {
        "id": "-uK8dOx511hb"
      }
    }
  ]
}