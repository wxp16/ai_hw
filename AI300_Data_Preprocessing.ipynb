{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AI300\n",
        "### Data Preprocessing\n",
        "\n",
        "Normalization may be needed for numerical data if the variables are on very different scales (if one is on terms of magnitude of maybe $10^4$ and the other is on terms of magnitude of maybe $10^1$.)"
      ],
      "metadata": {
        "id": "9aKFLNpqeCVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_size = 80\n",
        "test_size = 20\n",
        "num_features = 4\n",
        "\n",
        "np.random.seed(1)\n",
        "X_train = np.random.rand(train_size, num_features)\n",
        "X_test = np.random.rand(test_size, num_features)"
      ],
      "metadata": {
        "id": "IOYhIESye7Vr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMinMaxScaler():\n",
        "  def __init__(self):\n",
        "    self._min = None\n",
        "    self._max = None\n",
        "\n",
        "  def fit_transform(self, X_train):\n",
        "    self._min = np.min(X_train, axis = 0)\n",
        "    self._max = np.max(X_train, axis = 0)\n",
        "\n",
        "    transformed = (X_train - self._min) / (self._max - self._min)\n",
        "\n",
        "    return transformed\n",
        "\n",
        "  def transform(self, X_test):\n",
        "    transformed = (X_test - self._min) / (self._max - self._min)\n",
        "\n",
        "    return transformed"
      ],
      "metadata": {
        "id": "C8vOvZxIeZUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_minmax_scaler = MyMinMaxScaler()\n",
        "\n",
        "X_train_minmax_scaled = my_minmax_scaler.fit_transform(X_train)\n",
        "X_test_minmax_scaled = my_minmax_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "5MgkaA2ge5Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sklearn_minmax_scaler = MinMaxScaler()\n",
        "\n",
        "X_train_minmax_sklearn_scaled = sklearn_minmax_scaler.fit_transform(X_train)\n",
        "X_test_minmax_sklearn_scaled = sklearn_minmax_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ziL043VKfTV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(np.abs(X_train_minmax_scaled - X_train_minmax_sklearn_scaled)))\n",
        "print(np.max(np.abs(X_test_minmax_scaled - X_test_minmax_sklearn_scaled)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz_OgZJffiqO",
        "outputId": "f1fbecab-d8de-4607-d733-aab83c2ff47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1102230246251565e-16\n",
            "1.1102230246251565e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyStandardScaler():\n",
        "  def __init__(self):\n",
        "    self._mean = None\n",
        "    self._std = None\n",
        "\n",
        "  def fit_transform(self, X_train):\n",
        "    self._mean = np.mean(X_train, axis = 0)\n",
        "    self._std = np.std(X_train, axis = 0)\n",
        "\n",
        "    transformed = (X_train - self._mean) / (self._std)\n",
        "\n",
        "    return transformed\n",
        "\n",
        "  def transform(self, X_test):\n",
        "    transformed = (X_test - self._mean) / (self._std)\n",
        "\n",
        "    return transformed"
      ],
      "metadata": {
        "id": "65k_GWNRgWVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_standard_scaler = MyStandardScaler()\n",
        "\n",
        "X_train_standard_scaler = my_standard_scaler.fit_transform(X_train)\n",
        "X_test_standard_scaler = my_standard_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "_IJWE8trhLK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sklearn_standard_scaler = StandardScaler()\n",
        "\n",
        "X_train_sklearn_standard_scaler = sklearn_standard_scaler.fit_transform(X_train)\n",
        "X_test_sklearn_standard_scaler = sklearn_standard_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "NC__kk9uhbDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(np.abs(X_train_sklearn_standard_scaler - X_train_standard_scaler)))\n",
        "print(np.max(np.abs(X_test_sklearn_standard_scaler - X_test_standard_scaler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeaS7r69hzJO",
        "outputId": "eff75384-63bc-4f98-abbf-f63fb13c7f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewMyStandardScaler():\n",
        "  def __init__(self):\n",
        "    self._mean = None\n",
        "    self._std = None\n",
        "\n",
        "  def fit_transform(self, X_train):\n",
        "    self._mean = np.mean(X_train, axis = 0)\n",
        "    self._std = np.std(X_train, axis = 0)\n",
        "\n",
        "    transformed = (X_train - self._mean) / (self._std + 1e-16)\n",
        "\n",
        "    return transformed\n",
        "\n",
        "  def transform(self, X_test):\n",
        "    transformed = (X_test - self._mean) / (self._std + 1e-16)\n",
        "\n",
        "    return transformed"
      ],
      "metadata": {
        "id": "R2m2Zj_fiDew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no need to normalize a dataset that is all $1$ feature since you do not need to scale it compared to other variables since it is the only variable in the dataset, so you can just consider it without normalizing it since there is no other feature to compare to."
      ],
      "metadata": {
        "id": "Z2_hd4EjiRcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels1 = ['big', 'small', 'tall', 'short']\n",
        "labels2 = ['fish', 'elephant', 'dog', 'hamster']\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "np.random.seed(15)\n",
        "X = np.stack([np.random.choice(labels1, size = num_samples),\n",
        "             np.random.choice(labels2, size = num_samples)], axis = 1)"
      ],
      "metadata": {
        "id": "vJSZ6-tbidJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLabelEncoder():\n",
        "  def __init__(self):\n",
        "    self._classes = None\n",
        "\n",
        "  def fit(self, X):\n",
        "    self._classes = np.unique(X)\n",
        "\n",
        "  def transform(self, X):\n",
        "    encoded = np.zeros_like(X)\n",
        "    for i, label in enumerate(self._classes):\n",
        "      encoded[X == label] = i\n",
        "\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "NeR4oQ5_mCmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_label_encoded = np.empty_like(X)\n",
        "\n",
        "label_encoder = MyLabelEncoder()\n",
        "\n",
        "for i in range(X.shape[1]):\n",
        "  label_encoder.fit(X[:, i])\n",
        "  print(f\"Labels of feature {i} are: {label_encoder._classes}\")\n",
        "  X_label_encoded[:, i] = label_encoder.transform(X[:, i])\n",
        "\n",
        "print(X_label_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaIhpbpgmY1y",
        "outputId": "ca89dd97-8cff-4a20-a5b6-9d786f2d3e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels of feature 0 are: ['big' 'short' 'small']\n",
            "Labels of feature 1 are: ['dog' 'elephant' 'fish' 'hamster']\n",
            "[['0' '1']\n",
            " ['2' '0']\n",
            " ['0' '3']\n",
            " ['2' '1']\n",
            " ['1' '1']\n",
            " ['0' '1']\n",
            " ['0' '3']\n",
            " ['1' '3']\n",
            " ['1' '2']\n",
            " ['1' '0']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_label_encoded_sklearn = np.empty_like(X)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for i in range(X.shape[1]):\n",
        "  label_encoder.fit(X[:, i])\n",
        "  print(f\"Labels of feature {i} are: {label_encoder.classes_}\")\n",
        "  X_label_encoded_sklearn[:, i] = label_encoder.transform(X[:, i])\n",
        "\n",
        "print(X_label_encoded_sklearn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QKzIvoRmpNq",
        "outputId": "e801d4a9-f3e9-4acd-cf62-d58e6348a376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels of feature 0 are: ['big' 'short' 'small']\n",
            "Labels of feature 1 are: ['dog' 'elephant' 'fish' 'hamster']\n",
            "[['0' '1']\n",
            " ['2' '0']\n",
            " ['0' '3']\n",
            " ['2' '1']\n",
            " ['1' '1']\n",
            " ['0' '1']\n",
            " ['0' '3']\n",
            " ['1' '3']\n",
            " ['1' '2']\n",
            " ['1' '0']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.all(X_label_encoded == X_label_encoded_sklearn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRR3aX5Ym7ox",
        "outputId": "865eade8-7d63-488c-b969-a066bcccc110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyOneHotEncoder():\n",
        "  def __init__(self):\n",
        "    self._categories = None\n",
        "\n",
        "  def fit(self, X):\n",
        "    self._categories = []\n",
        "    for i in range(X.shape[1]):\n",
        "      self._categories.append(np.unique(X[:, i]))\n",
        "\n",
        "  def transform(self, X):\n",
        "    col_num = 0\n",
        "    for i in range(X.shape[1]):\n",
        "      col_num += len(self._categories[i])\n",
        "\n",
        "    encoded = np.zeros(shape = (X.shape[0], col_num))\n",
        "\n",
        "    col_index = 0\n",
        "    for i in range(X.shape[1]):\n",
        "      for label in self._categories[i]:\n",
        "        encoded[X[:, i] == label, col_index] = 1\n",
        "        col_index += 1\n",
        "\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "KU0UujeVnHmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = MyOneHotEncoder()\n",
        "\n",
        "one_hot_encoder.fit(X)\n",
        "X_one_hot_encoder = one_hot_encoder.transform(X)"
      ],
      "metadata": {
        "id": "DxqGmZ0Tqn_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_encoder_sklearn = OneHotEncoder()\n",
        "\n",
        "one_hot_encoder_sklearn.fit(X)\n",
        "X_one_hot_encoder_sklearn = one_hot_encoder_sklearn.transform(X)"
      ],
      "metadata": {
        "id": "ECbfTX1qqjpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.all(X_one_hot_encoder == X_one_hot_encoder_sklearn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZfLmjz0rDZa",
        "outputId": "12a98639-d8c3-435d-8a85-29d0929b0912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "dataset = load_iris()"
      ],
      "metadata": {
        "id": "Lfdi9m-svjZA"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if np.isnan(dataset.data).any():\n",
        "    dataset.data = dataset.data[~np.isnan(dataset).any(axis=1)]\n",
        "\n",
        "dataset.data = np.unique(dataset.data, axis=1)"
      ],
      "metadata": {
        "id": "N67zr9BKzOid"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = np.ones((dataset.data.shape[0], 1))\n",
        "dataset.data = np.hstack([dataset.data, ones])"
      ],
      "metadata": {
        "id": "ulwTyIzH1kRV"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "for i in range(dataset.data.shape[1]):\n",
        "  scaled = standard_scaler.fit_transform(dataset.data[:, i].reshape(-1, 1))\n",
        "  dataset.data[:, i] = scaled.flatten()"
      ],
      "metadata": {
        "id": "w8VW73xKripC"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "\n",
        "one_hot_encoder.fit(dataset.target.reshape(-1, 1))\n",
        "one_hot_encoded = one_hot_encoder.transform(dataset.target.reshape(-1, 1))\n",
        "dataset.target = one_hot_encoded"
      ],
      "metadata": {
        "id": "vh4XLUiAyBto"
      },
      "execution_count": 119,
      "outputs": []
    }
  ]
}